In this project, we explored deep learning techniques for driver inattention classification, leveraging convolutional neural networks (CNNs) and transfer learning. Starting with a baseline model with a validation accuracy of 78.97%. We randomly selected 15 samples from different driving conditions. The results reveal a significant imbalance in class representation. This imbalance impacts model training, making it more difficult for the network to learn minority class features effectively. However, addressing this imbalance through data augmentation or class weighting did not improve overall model performance.
We firs conducted a baseline model, consisting of 3 convolution layers with 8 filters each, followed by a simple dense structure and trained using the Adam optimizer, demonstrated moderate performance but showed signs of overfitting. With a training accuracy of 83.64% and a validation accuracy of 78.97%, it was evident that the model was struggling to generalize. Its shallow architecture limited feature extraction, while the lack of regularization made it overly sensitive to training data. 
We trained three neural networl models to improve upon the baseline model. We systematically improved performance through hyperparameter tuning, architectural modifications, and the application of advanced techniques such as batch normalization, dropout, and data augmentation and transfer learning. 
Our best model demonstrated a significant improvement over the baseline in all performance metrics. The ROC curve comparison shows that the best model consistently achieved higher AUC scores across all classes. The confusion matrix further illustrates the reduction in misclassifications. The baseline model had frequent misclassifications between the ’Distracted’ and ’Safe Driving’ categories. While these categories saw the most improvement in the best model, they remain the most commonly confused pair. The recall score for the baseline model was relatively low (0.65), indicating poor performance in minority classes . In contrast, the best model achieved a recall of 0.92, indicating a much stronger capability to correctly identify instances across all classes. The architectural enhancements, including additional convolutional layers, increased filter sizes in deeper layers, optimized dropout rates, and batch normalization, significantly contributed to improved feature extraction and reduced overfitting.
Transfer learning experiments with DenseNet121 improved compared to the baseline model, but performed worse than our custom CNN model. This could be that the pre-trained features were not well-suited for the dataset, and freezing most convolutional layers limited the model’s ability to adapt to the specific task.
